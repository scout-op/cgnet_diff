"""
Anchoråˆ†æè„šæœ¬
è¯„ä¼°å’Œç»Ÿè®¡anchorçš„åˆ†å¸ƒä¿¡æ¯
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from scipy.spatial.distance import pdist, squareform
import argparse


def parse_args():
    parser = argparse.ArgumentParser(description='Analyze anchor distribution')
    parser.add_argument('--anchor-file', default='work_dirs/kmeans_anchors.pth',
                       help='Path to anchor file')
    parser.add_argument('--output-dir', default='work_dirs/anchor_analysis',
                       help='Output directory for analysis results')
    return parser.parse_args()


def bezier_interpolate(ctrl_points, num_points=50):
    """è´å¡å°”æ’å€¼"""
    from math import factorial
    
    def comb(n, k):
        return factorial(n) // (factorial(k) * factorial(n - k))
    
    n_control = len(ctrl_points)
    degree = n_control - 1
    
    t = np.linspace(0, 1, num_points)
    points = np.zeros((num_points, 2))
    
    for i in range(n_control):
        coef = comb(degree, i) * np.power(1 - t, degree - i) * np.power(t, i)
        points += coef[:, np.newaxis] * ctrl_points[i]
    
    return points


def compute_curve_direction(ctrl_points):
    """è®¡ç®—æ›²çº¿çš„ä¸»æ–¹å‘"""
    start = ctrl_points[0]
    end = ctrl_points[-1]
    
    dx = end[0] - start[0]
    dy = end[1] - start[1]
    
    angle = np.arctan2(dy, dx) * 180 / np.pi
    
    return angle


def compute_curve_length(ctrl_points, num_samples=50):
    """è®¡ç®—æ›²çº¿é•¿åº¦"""
    points = bezier_interpolate(ctrl_points, num_samples)
    
    diffs = np.diff(points, axis=0)
    lengths = np.linalg.norm(diffs, axis=1)
    total_length = lengths.sum()
    
    return total_length


def compute_curvature(ctrl_points):
    """è®¡ç®—æ›²çº¿çš„å¹³å‡æ›²ç‡"""
    points = bezier_interpolate(ctrl_points, 50)
    
    dx = np.gradient(points[:, 0])
    dy = np.gradient(points[:, 1])
    ddx = np.gradient(dx)
    ddy = np.gradient(dy)
    
    curvature = np.abs(dx * ddy - dy * ddx) / (dx**2 + dy**2)**1.5
    curvature = np.nan_to_num(curvature)
    
    return curvature.mean()


def classify_anchor_type(ctrl_points):
    """åˆ†ç±»anchorç±»å‹"""
    angle = compute_curve_direction(ctrl_points)
    curvature = compute_curvature(ctrl_points)
    
    if curvature < 0.01:
        return 'straight'
    elif angle > 45:
        return 'left_turn'
    elif angle < -45:
        return 'right_turn'
    elif abs(angle) < 45:
        if curvature < 0.05:
            return 'straight'
        else:
            return 'curved'
    else:
        return 'other'


def analyze_anchors(anchor_file, output_dir):
    """åˆ†æanchoråˆ†å¸ƒ"""
    import os
    os.makedirs(output_dir, exist_ok=True)
    
    print("="*70)
    print("ğŸ” Anchoråˆ†å¸ƒåˆ†æ")
    print("="*70)
    
    data = torch.load(anchor_file)
    anchors = data['anchors'].numpy()
    
    print(f"\nåŸºæœ¬ä¿¡æ¯:")
    print(f"  Anchoræ•°é‡: {len(anchors)}")
    print(f"  æ§åˆ¶ç‚¹æ•°: {anchors.shape[1]}")
    print(f"  åæ ‡ç»´åº¦: {anchors.shape[2]}")
    print(f"  æ€»å½¢çŠ¶: {anchors.shape}")
    
    print(f"\nåæ ‡èŒƒå›´:")
    print(f"  X: [{anchors[:, :, 0].min():.2f}, {anchors[:, :, 0].max():.2f}]")
    print(f"  Y: [{anchors[:, :, 1].min():.2f}, {anchors[:, :, 1].max():.2f}]")
    
    print("\n" + "-"*70)
    print("ç»Ÿè®¡åˆ†æ:")
    print("-"*70)
    
    lengths = []
    curvatures = []
    directions = []
    types = {'straight': 0, 'left_turn': 0, 'right_turn': 0, 'curved': 0, 'other': 0}
    
    for i, anchor in enumerate(anchors):
        length = compute_curve_length(anchor)
        curvature = compute_curvature(anchor)
        direction = compute_curve_direction(anchor)
        anchor_type = classify_anchor_type(anchor)
        
        lengths.append(length)
        curvatures.append(curvature)
        directions.append(direction)
        types[anchor_type] += 1
    
    lengths = np.array(lengths)
    curvatures = np.array(curvatures)
    directions = np.array(directions)
    
    print(f"\né•¿åº¦ç»Ÿè®¡:")
    print(f"  å¹³å‡: {lengths.mean():.2f} m")
    print(f"  æœ€å°: {lengths.min():.2f} m")
    print(f"  æœ€å¤§: {lengths.max():.2f} m")
    print(f"  æ ‡å‡†å·®: {lengths.std():.2f} m")
    
    print(f"\næ›²ç‡ç»Ÿè®¡:")
    print(f"  å¹³å‡: {curvatures.mean():.4f}")
    print(f"  æœ€å°: {curvatures.min():.4f}")
    print(f"  æœ€å¤§: {curvatures.max():.4f}")
    
    print(f"\næ–¹å‘ç»Ÿè®¡:")
    print(f"  å¹³å‡è§’åº¦: {directions.mean():.2f}Â°")
    print(f"  è§’åº¦èŒƒå›´: [{directions.min():.2f}Â°, {directions.max():.2f}Â°]")
    
    print(f"\nç±»å‹åˆ†å¸ƒ:")
    total = sum(types.values())
    for anchor_type, count in sorted(types.items(), key=lambda x: -x[1]):
        percentage = count / total * 100
        print(f"  {anchor_type:12s}: {count:3d} ({percentage:5.1f}%)")
    
    print("\n" + "-"*70)
    print("å¤šæ ·æ€§åˆ†æ:")
    print("-"*70)
    
    anchors_flat = anchors.reshape(len(anchors), -1)
    distances = pdist(anchors_flat, metric='euclidean')
    
    print(f"\nAnchoré—´è·ç¦»:")
    print(f"  å¹³å‡: {distances.mean():.2f}")
    print(f"  æœ€å°: {distances.min():.2f} (æœ€ç›¸ä¼¼çš„ä¸¤ä¸ªanchor)")
    print(f"  æœ€å¤§: {distances.max():.2f} (æœ€ä¸åŒçš„ä¸¤ä¸ªanchor)")
    print(f"  æ ‡å‡†å·®: {distances.std():.2f}")
    
    diversity_score = distances.mean() / distances.std()
    print(f"\nå¤šæ ·æ€§å¾—åˆ†: {diversity_score:.2f}")
    if diversity_score > 1.0:
        print("  âœ… å¤šæ ·æ€§è‰¯å¥½")
    else:
        print("  âš ï¸ å¤šæ ·æ€§è¾ƒä½ï¼Œanchorå¯èƒ½è¿‡äºç›¸ä¼¼")
    
    print("\n" + "-"*70)
    print("å¯è§†åŒ–ç”Ÿæˆ:")
    print("-"*70)
    
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    
    ax = axes[0, 0]
    ax.hist(lengths, bins=20, edgecolor='black', alpha=0.7)
    ax.set_xlabel('Length (m)')
    ax.set_ylabel('Count')
    ax.set_title('Anchor Length Distribution')
    ax.grid(True, alpha=0.3)
    
    ax = axes[0, 1]
    ax.hist(curvatures, bins=20, edgecolor='black', alpha=0.7)
    ax.set_xlabel('Curvature')
    ax.set_ylabel('Count')
    ax.set_title('Anchor Curvature Distribution')
    ax.grid(True, alpha=0.3)
    
    ax = axes[0, 2]
    ax.hist(directions, bins=30, edgecolor='black', alpha=0.7)
    ax.set_xlabel('Direction (degrees)')
    ax.set_ylabel('Count')
    ax.set_title('Anchor Direction Distribution')
    ax.axvline(0, color='r', linestyle='--', label='Forward')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    ax = axes[1, 0]
    type_names = list(types.keys())
    type_counts = [types[t] for t in type_names]
    ax.bar(type_names, type_counts, edgecolor='black', alpha=0.7)
    ax.set_ylabel('Count')
    ax.set_title('Anchor Type Distribution')
    ax.grid(True, alpha=0.3, axis='y')
    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')
    
    ax = axes[1, 1]
    dist_matrix = squareform(distances)
    im = ax.imshow(dist_matrix, cmap='viridis', aspect='auto')
    ax.set_xlabel('Anchor Index')
    ax.set_ylabel('Anchor Index')
    ax.set_title('Pairwise Distance Matrix')
    plt.colorbar(im, ax=ax)
    
    ax = axes[1, 2]
    for i, anchor in enumerate(anchors[::5]):
        points = bezier_interpolate(anchor)
        ax.plot(points[:, 0], points[:, 1], alpha=0.5, linewidth=1)
    ax.set_xlim(-15, 15)
    ax.set_ylim(-30, 30)
    ax.set_xlabel('X (m)')
    ax.set_ylabel('Y (m)')
    ax.set_title('Sample Anchors (every 5th)')
    ax.grid(True, alpha=0.3)
    ax.set_aspect('equal')
    
    plt.tight_layout()
    save_path = f'{output_dir}/anchor_statistics.png'
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"\nâœ… ç»Ÿè®¡å›¾å·²ä¿å­˜: {save_path}")
    plt.close()
    
    print("\n" + "="*70)
    print("ğŸ“Š åˆ†ææŠ¥å‘Š")
    print("="*70)
    
    report = []
    report.append("Anchorè´¨é‡è¯„ä¼°:\n")
    
    if len(anchors) >= 30:
        report.append("âœ… æ•°é‡å……è¶³ (>= 30)")
    else:
        report.append("âš ï¸ æ•°é‡è¾ƒå°‘ (< 30)")
    
    if types['straight'] > len(anchors) * 0.3:
        report.append("âœ… ç›´è¡Œè½¦é“å……è¶³")
    else:
        report.append("âš ï¸ ç›´è¡Œè½¦é“è¾ƒå°‘")
    
    if types['left_turn'] > 5 and types['right_turn'] > 5:
        report.append("âœ… è½¬å¼¯è½¦é“è¦†ç›–è‰¯å¥½")
    else:
        report.append("âš ï¸ è½¬å¼¯è½¦é“è¦†ç›–ä¸è¶³")
    
    if diversity_score > 1.0:
        report.append("âœ… å¤šæ ·æ€§è‰¯å¥½")
    else:
        report.append("âš ï¸ å¤šæ ·æ€§ä¸è¶³")
    
    if lengths.std() / lengths.mean() > 0.3:
        report.append("âœ… é•¿åº¦åˆ†å¸ƒå¤šæ ·")
    else:
        report.append("âš ï¸ é•¿åº¦åˆ†å¸ƒå•ä¸€")
    
    print("\n".join(report))
    
    with open(f'{output_dir}/analysis_report.txt', 'w') as f:
        f.write("Anchoråˆ†å¸ƒåˆ†ææŠ¥å‘Š\n")
        f.write("="*70 + "\n\n")
        f.write(f"åŸºæœ¬ä¿¡æ¯:\n")
        f.write(f"  æ•°é‡: {len(anchors)}\n")
        f.write(f"  å½¢çŠ¶: {anchors.shape}\n\n")
        f.write(f"åæ ‡èŒƒå›´:\n")
        f.write(f"  X: [{anchors[:, :, 0].min():.2f}, {anchors[:, :, 0].max():.2f}]\n")
        f.write(f"  Y: [{anchors[:, :, 1].min():.2f}, {anchors[:, :, 1].max():.2f}]\n\n")
        f.write(f"é•¿åº¦ç»Ÿè®¡:\n")
        f.write(f"  å¹³å‡: {lengths.mean():.2f} m\n")
        f.write(f"  èŒƒå›´: [{lengths.min():.2f}, {lengths.max():.2f}] m\n")
        f.write(f"  æ ‡å‡†å·®: {lengths.std():.2f} m\n\n")
        f.write(f"ç±»å‹åˆ†å¸ƒ:\n")
        for t, c in sorted(types.items(), key=lambda x: -x[1]):
            f.write(f"  {t}: {c} ({c/total*100:.1f}%)\n")
        f.write(f"\nå¤šæ ·æ€§å¾—åˆ†: {diversity_score:.2f}\n\n")
        f.write("è´¨é‡è¯„ä¼°:\n")
        f.write("\n".join(report))
    
    print(f"\nâœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {output_dir}/analysis_report.txt")
    
    print("\n" + "="*70)
    print("âœ… åˆ†æå®Œæˆï¼")
    print("="*70)
    
    return {
        'num_anchors': len(anchors),
        'length_mean': lengths.mean(),
        'length_std': lengths.std(),
        'diversity_score': diversity_score,
        'types': types
    }


if __name__ == '__main__':
    args = parse_args()
    
    try:
        stats = analyze_anchors(args.anchor_file, args.output_dir)
        
        print("\n" + "="*70)
        print("ğŸ“‹ å¿«é€Ÿæ€»ç»“")
        print("="*70)
        print(f"Anchoræ•°é‡: {stats['num_anchors']}")
        print(f"å¹³å‡é•¿åº¦: {stats['length_mean']:.2f} m")
        print(f"å¤šæ ·æ€§å¾—åˆ†: {stats['diversity_score']:.2f}")
        print(f"ä¸»è¦ç±»å‹: {max(stats['types'].items(), key=lambda x: x[1])}")
        
        if stats['diversity_score'] > 1.0 and stats['num_anchors'] >= 30:
            print("\nâœ… Anchorè´¨é‡è‰¯å¥½ï¼Œå¯ä»¥ç”¨äºè®­ç»ƒï¼")
        else:
            print("\nâš ï¸ Anchorè´¨é‡ä¸€èˆ¬ï¼Œå»ºè®®æ£€æŸ¥æ•°æ®æˆ–è°ƒæ•´èšç±»å‚æ•°")
        
    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
