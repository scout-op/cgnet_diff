import torch
import torch.nn as nn
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np


def check_gradients(model, verbose=False):
    """
    æ£€æŸ¥æ¢¯åº¦æ˜¯å¦æ­£å¸¸
    
    Args:
        model: nn.Module
        verbose: bool, æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
    
    Returns:
        is_valid: bool, æ¢¯åº¦æ˜¯å¦æ­£å¸¸
    """
    has_nan = False
    has_inf = False
    
    for name, param in model.named_parameters():
        if param.grad is not None:
            grad_norm = param.grad.norm()
            
            if torch.isnan(grad_norm):
                print(f"âŒ NaNæ¢¯åº¦: {name}")
                has_nan = True
            
            if torch.isinf(grad_norm):
                print(f"âŒ Infæ¢¯åº¦: {name}, norm={grad_norm}")
                has_inf = True
            
            if verbose and grad_norm > 100:
                print(f"âš ï¸  å¤§æ¢¯åº¦: {name}, norm={grad_norm:.2f}")
    
    return not (has_nan or has_inf)


def sanity_check_overfit(model, dataset, num_steps=1000, lr=1e-4):
    """
    è¿‡æ‹Ÿåˆæµ‹è¯•ï¼šåœ¨1ä¸ªbatchä¸Šè®­ç»ƒï¼ŒéªŒè¯ä»£ç é€»è¾‘
    
    Args:
        model: DiffCGNetæ¨¡å‹
        dataset: æ•°æ®é›†
        num_steps: è®­ç»ƒæ­¥æ•°
        lr: å­¦ä¹ ç‡
    
    Returns:
        success: bool, æ˜¯å¦é€šè¿‡æµ‹è¯•
    """
    print("="*70)
    print("ğŸ§ª å¼€å§‹ Sanity Checkï¼ˆè¿‡æ‹Ÿåˆæµ‹è¯•ï¼‰")
    print("="*70)
    print("ç›®æ ‡: åœ¨1ä¸ªæ ·æœ¬ä¸Šå®Œç¾è¿‡æ‹Ÿåˆ")
    print("æ ‡å‡†: Loss < 0.01, å‡ ä½•è¯¯å·® < 0.5m, æ‹“æ‰‘å‡†ç¡®ç‡ > 95%")
    print("="*70)
    
    single_sample = [dataset[0]]
    mini_loader = DataLoader(single_sample, batch_size=1, shuffle=False)
    
    model = model.cuda()
    model.train()
    
    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)
    
    losses = []
    geo_errors = []
    
    print("\nå¼€å§‹è®­ç»ƒ...")
    for step in range(num_steps):
        batch = next(iter(mini_loader))
        
        for key in batch:
            if isinstance(batch[key], torch.Tensor):
                batch[key] = batch[key].cuda()
        
        loss_dict = model.forward_train(
            batch['img'],
            batch['gt_bboxes_3d'],
            batch['gt_labels_3d'],
            epoch=0
        )
        
        loss = sum(loss_dict.values())
        
        optimizer.zero_grad()
        loss.backward()
        
        if not check_gradients(model, verbose=(step % 100 == 0)):
            print(f"\nâŒ Step {step}: æ¢¯åº¦å¼‚å¸¸ï¼")
            return False
        
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=35)
        
        optimizer.step()
        
        losses.append(loss.item())
        
        if step % 100 == 0:
            print(f"Step {step:4d}: Loss = {loss.item():.6f}")
            for k, v in loss_dict.items():
                print(f"  - {k}: {v.item():.6f}")
    
    final_loss = losses[-1]
    
    print("\n" + "="*70)
    print("ğŸ“Š Sanity Check ç»“æœ:")
    print("="*70)
    
    success = True
    
    if final_loss < 0.01:
        print(f"âœ… Lossæ”¶æ•›: {final_loss:.6f} < 0.01")
    else:
        print(f"âŒ Lossæœªæ”¶æ•›: {final_loss:.6f} >= 0.01")
        print("   å¯èƒ½çš„é—®é¢˜:")
        print("   - åŒ¹é…é€»è¾‘é”™è¯¯")
        print("   - æŸå¤±å‡½æ•°è®¡ç®—é”™è¯¯")
        print("   - å­¦ä¹ ç‡å¤ªå°æˆ–å¤ªå¤§")
        print("   - æ•°æ®é¢„å¤„ç†é”™è¯¯")
        success = False
    
    model.eval()
    with torch.no_grad():
        batch = next(iter(mini_loader))
        for key in batch:
            if isinstance(batch[key], torch.Tensor):
                batch[key] = batch[key].cuda()
        
        results = model.forward_test(batch['img'], batch['img_metas'])
    
    print("\n" + "="*70)
    if success:
        print("âœ…âœ…âœ… Sanity Check å®Œå…¨é€šè¿‡ï¼")
        print("å¯ä»¥å¼€å§‹å…¨é‡è®­ç»ƒï¼")
    else:
        print("âŒâŒâŒ Sanity Check å¤±è´¥ï¼")
        print("è¯·å…ˆDebugï¼Œä¸è¦æµªè´¹æ—¶é—´è·‘å…¨é‡æ•°æ®ï¼")
    print("="*70)
    
    plt.figure(figsize=(10, 5))
    plt.plot(losses)
    plt.xlabel('Step')
    plt.ylabel('Loss')
    plt.title('Sanity Check: Loss Curve')
    plt.grid(True, alpha=0.3)
    plt.yscale('log')
    plt.savefig('work_dirs/sanity_check_loss.png', dpi=150, bbox_inches='tight')
    print(f"\nğŸ“ˆ Lossæ›²çº¿å·²ä¿å­˜åˆ°: work_dirs/sanity_check_loss.png")
    
    return success


if __name__ == '__main__':
    print("è¯·å…ˆå®ç°å®Œæ•´çš„DiffCGNetæ¨¡å‹ï¼Œç„¶åè°ƒç”¨æ­¤è„šæœ¬")
    print("ç”¨æ³•: python tools/test_sanity_check.py --config configs/... --checkpoint ...")
